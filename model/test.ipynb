{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T05:53:22.248779Z",
     "start_time": "2024-11-27T05:53:22.235201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from model.data_util import *\n",
    "from sklearn.metrics import *\n",
    "from imbens.metrics import *\n",
    "from imbens.ensemble import *\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from imbens.datasets import fetch_datasets\n",
    "from collections import Counter"
   ],
   "id": "598cf2fafac5bc1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T05:53:22.452680Z",
     "start_time": "2024-11-27T05:53:22.257248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "# X, y, dataset_name = get_ecoli1()\n",
    "dataset = fetch_datasets()['us_crime']\n",
    "X, y = dataset['data'], dataset['target']\n",
    "print(Counter(y))\n",
    "dataset_name = 'us_crime'\n",
    "# 将-1类别转换为0\n",
    "y = np.where(y == -1, 0, y)\n",
    "print(Counter(y))"
   ],
   "id": "5053696f899106a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({-1: 1844, 1: 150})\n",
      "Counter({0: 1844, 1: 150})\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T05:53:31.312266Z",
     "start_time": "2024-11-27T05:53:22.469640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs = []\n",
    "f1s = []\n",
    "precs = []\n",
    "recs = []\n",
    "gmeans = []\n",
    "aucs = []\n",
    "auprs = []\n",
    "sens = []\n",
    "spes = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = SelfPacedEnsembleClassifier(n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    accs.append(accuracy_score(y_test, y_pred))\n",
    "    f1s.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    precs.append(precision_score(y_test, y_pred, average='macro'))\n",
    "    recs.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    gmeans.append(geometric_mean_score(y_test, y_pred))\n",
    "    aucs.append(roc_auc_score(y_test, y_pred_proba))\n",
    "    auprs.append(average_precision_score(y_test, y_pred_proba))\n",
    "    sens.append(sensitivity_score(y_test, y_pred))\n",
    "    spes.append(specificity_score(y_test, y_pred))\n",
    "    \n",
    "print('model:', model.__class__)\n",
    "print('dataset:', dataset_name)\n",
    "print('Accuracy:', np.mean(accs))\n",
    "print('F1:', np.mean(f1s))\n",
    "print('Precision:', np.mean(precs))\n",
    "print('Recall:', np.mean(recs))\n",
    "print('G-mean:', np.mean(gmeans))\n",
    "print('AUC:', np.mean(aucs))\n",
    "print('AUPR:', np.mean(auprs))\n",
    "print('Sensitivity:', np.mean(sens))\n",
    "print('Specificity:', np.mean(spes))"
   ],
   "id": "7af490e40b3001ca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority class detected: 0\n",
      "Majority class detected: 0\n",
      "Majority class detected: 0\n",
      "Majority class detected: 0\n",
      "Majority class detected: 0\n",
      "model: <class 'imbens.ensemble._under_sampling.self_paced_ensemble.SelfPacedEnsembleClassifier'>\n",
      "dataset: us_crime\n",
      "Accuracy: 0.910734121736502\n",
      "F1: 0.7415072785151271\n",
      "Precision: 0.7114650920362949\n",
      "Recall: 0.8016911158242017\n",
      "G-mean: 0.7888548307883955\n",
      "AUC: 0.91511981560033\n",
      "AUPR: 0.5694553793150475\n",
      "Sensitivity: 0.6733333333333333\n",
      "Specificity: 0.9300488983150702\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T05:53:34.156202Z",
     "start_time": "2024-11-27T05:53:31.344308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs = []\n",
    "f1s = []\n",
    "precs = []\n",
    "recs = []\n",
    "gmeans = []\n",
    "aucs = []\n",
    "auprs = []\n",
    "sens = []\n",
    "spes = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = BalanceCascadeClassifier(n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    accs.append(accuracy_score(y_test, y_pred))\n",
    "    f1s.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    precs.append(precision_score(y_test, y_pred, average='macro'))\n",
    "    recs.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    gmeans.append(geometric_mean_score(y_test, y_pred))\n",
    "    aucs.append(roc_auc_score(y_test, y_pred_proba))\n",
    "    auprs.append(average_precision_score(y_test, y_pred_proba))\n",
    "    sens.append(sensitivity_score(y_test, y_pred))\n",
    "    spes.append(specificity_score(y_test, y_pred))\n",
    "    \n",
    "print('model:', model.__class__)\n",
    "print('dataset:', dataset_name)\n",
    "print('Accuracy:', np.mean(accs))\n",
    "print('F1:', np.mean(f1s))\n",
    "print('Precision:', np.mean(precs))\n",
    "print('Recall:', np.mean(recs))\n",
    "print('G-mean:', np.mean(gmeans))\n",
    "print('AUC:', np.mean(aucs))\n",
    "print('AUPR:', np.mean(auprs))\n",
    "print('Sensitivity:', np.mean(sens))\n",
    "print('Specificity:', np.mean(spes))"
   ],
   "id": "8bdb290db1082edf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: <class 'imbens.ensemble._under_sampling.balance_cascade.BalanceCascadeClassifier'>\n",
      "dataset: us_crime\n",
      "Accuracy: 0.9027014773113688\n",
      "F1: 0.709956291540802\n",
      "Precision: 0.6847589502660177\n",
      "Recall: 0.7606041593024625\n",
      "G-mean: 0.7356733596970557\n",
      "AUC: 0.8946668679549115\n",
      "AUPR: 0.5518082762950063\n",
      "Sensitivity: 0.5933333333333333\n",
      "Specificity: 0.9278749852715918\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T05:53:39.610115Z",
     "start_time": "2024-11-27T05:53:34.165574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs = []\n",
    "f1s = []\n",
    "precs = []\n",
    "recs = []\n",
    "gmeans = []\n",
    "aucs = []\n",
    "auprs = []\n",
    "sens = []\n",
    "spes = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = UnderBaggingClassifier(n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    accs.append(accuracy_score(y_test, y_pred))\n",
    "    f1s.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    precs.append(precision_score(y_test, y_pred, average='macro'))\n",
    "    recs.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    gmeans.append(geometric_mean_score(y_test, y_pred))\n",
    "    aucs.append(roc_auc_score(y_test, y_pred_proba))\n",
    "    auprs.append(average_precision_score(y_test, y_pred_proba))\n",
    "    sens.append(sensitivity_score(y_test, y_pred))\n",
    "    spes.append(specificity_score(y_test, y_pred))\n",
    "    \n",
    "print('model:', model.__class__)\n",
    "print('dataset:', dataset_name)\n",
    "print('Accuracy:', np.mean(accs))\n",
    "print('F1:', np.mean(f1s))\n",
    "print('Precision:', np.mean(precs))\n",
    "print('Recall:', np.mean(recs))\n",
    "print('G-mean:', np.mean(gmeans))\n",
    "print('AUC:', np.mean(aucs))\n",
    "print('AUPR:', np.mean(auprs))\n",
    "print('Sensitivity:', np.mean(sens))\n",
    "print('Specificity:', np.mean(spes))"
   ],
   "id": "9066e199f76b930c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: <class 'imbens.ensemble._under_sampling.under_bagging.UnderBaggingClassifier'>\n",
      "dataset: us_crime\n",
      "Accuracy: 0.8620936764020606\n",
      "F1: 0.7018938720407076\n",
      "Precision: 0.6642049390188748\n",
      "Recall: 0.855008247908566\n",
      "G-mean: 0.853183253531242\n",
      "AUC: 0.9115876487569224\n",
      "AUPR: 0.4801817544532755\n",
      "Sensitivity: 0.8466666666666667\n",
      "Specificity: 0.8633498291504654\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T05:53:41.550101Z",
     "start_time": "2024-11-27T05:53:39.626249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs = []\n",
    "f1s = []\n",
    "precs = []\n",
    "recs = []\n",
    "gmeans = []\n",
    "aucs = []\n",
    "auprs = []\n",
    "sens = []\n",
    "spes = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = EasyEnsembleClassifier(n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    accs.append(accuracy_score(y_test, y_pred))\n",
    "    f1s.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    precs.append(precision_score(y_test, y_pred, average='macro'))\n",
    "    recs.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    gmeans.append(geometric_mean_score(y_test, y_pred))\n",
    "    aucs.append(roc_auc_score(y_test, y_pred_proba))\n",
    "    auprs.append(average_precision_score(y_test, y_pred_proba))\n",
    "    sens.append(sensitivity_score(y_test, y_pred))\n",
    "    spes.append(specificity_score(y_test, y_pred))\n",
    "    \n",
    "print('model:', model.__class__)\n",
    "print('dataset:', dataset_name)\n",
    "print('Accuracy:', np.mean(accs))\n",
    "print('F1:', np.mean(f1s))\n",
    "print('Precision:', np.mean(precs))\n",
    "print('Recall:', np.mean(recs))\n",
    "print('G-mean:', np.mean(gmeans))\n",
    "print('AUC:', np.mean(aucs))\n",
    "print('AUPR:', np.mean(auprs))\n",
    "print('Sensitivity:', np.mean(sens))\n",
    "print('Specificity:', np.mean(spes))"
   ],
   "id": "9acec79c5dde6b4d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: <class 'imbens.ensemble._under_sampling.easy_ensemble.EasyEnsembleClassifier'>\n",
      "dataset: us_crime\n",
      "Accuracy: 0.8525635697283409\n",
      "F1: 0.6924169959793665\n",
      "Precision: 0.6574552364628645\n",
      "Recall: 0.8559794391422175\n",
      "G-mean: 0.8538971894710349\n",
      "AUC: 0.9268088449000432\n",
      "AUPR: 0.6081564370021083\n",
      "Sensitivity: 0.8600000000000001\n",
      "Specificity: 0.851958878284435\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T05:53:42.359732Z",
     "start_time": "2024-11-27T05:53:41.567164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs = []\n",
    "f1s = []\n",
    "precs = []\n",
    "recs = []\n",
    "gmeans = []\n",
    "aucs = []\n",
    "auprs = []\n",
    "sens = []\n",
    "spes = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = RUSBoostClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    accs.append(accuracy_score(y_test, y_pred))\n",
    "    f1s.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    precs.append(precision_score(y_test, y_pred, average='macro'))\n",
    "    recs.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    gmeans.append(geometric_mean_score(y_test, y_pred))\n",
    "    aucs.append(roc_auc_score(y_test, y_pred_proba))\n",
    "    auprs.append(average_precision_score(y_test, y_pred_proba))\n",
    "    sens.append(sensitivity_score(y_test, y_pred))\n",
    "    spes.append(specificity_score(y_test, y_pred))\n",
    "    \n",
    "print('model:', model.__class__)\n",
    "print('dataset:', dataset_name)\n",
    "print('Accuracy:', np.mean(accs))\n",
    "print('F1:', np.mean(f1s))\n",
    "print('Precision:', np.mean(precs))\n",
    "print('Recall:', np.mean(recs))\n",
    "print('G-mean:', np.mean(gmeans))\n",
    "print('AUC:', np.mean(aucs))\n",
    "print('AUPR:', np.mean(auprs))\n",
    "print('Sensitivity:', np.mean(sens))\n",
    "print('Specificity:', np.mean(spes))"
   ],
   "id": "f45addb8dcff339a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: <class 'imbens.ensemble._under_sampling.rus_boost.RUSBoostClassifier'>\n",
      "dataset: us_crime\n",
      "Accuracy: 0.8139582624903967\n",
      "F1: 0.5863985956331289\n",
      "Precision: 0.5764402309226915\n",
      "Recall: 0.6574992635795922\n",
      "G-mean: 0.6281426387367932\n",
      "AUC: 0.7621840756451042\n",
      "AUPR: 0.266620362535101\n",
      "Sensitivity: 0.4733333333333333\n",
      "Specificity: 0.8416651938258513\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T05:53:43.290165Z",
     "start_time": "2024-11-27T05:53:42.376260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs = []\n",
    "f1s = []\n",
    "precs = []\n",
    "recs = []\n",
    "gmeans = []\n",
    "aucs = []\n",
    "auprs = []\n",
    "sens = []\n",
    "spes = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = BalancedRandomForestClassifier(n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    accs.append(accuracy_score(y_test, y_pred))\n",
    "    f1s.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    precs.append(precision_score(y_test, y_pred, average='macro'))\n",
    "    recs.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    gmeans.append(geometric_mean_score(y_test, y_pred))\n",
    "    aucs.append(roc_auc_score(y_test, y_pred_proba))\n",
    "    auprs.append(average_precision_score(y_test, y_pred_proba))\n",
    "    sens.append(sensitivity_score(y_test, y_pred))\n",
    "    spes.append(specificity_score(y_test, y_pred))\n",
    "    \n",
    "print('model:', model.__class__)\n",
    "print('dataset:', dataset_name)\n",
    "print('Accuracy:', np.mean(accs))\n",
    "print('F1:', np.mean(f1s))\n",
    "print('Precision:', np.mean(precs))\n",
    "print('Recall:', np.mean(recs))\n",
    "print('G-mean:', np.mean(gmeans))\n",
    "print('AUC:', np.mean(aucs))\n",
    "print('AUPR:', np.mean(auprs))\n",
    "print('Sensitivity:', np.mean(sens))\n",
    "print('Specificity:', np.mean(spes))"
   ],
   "id": "3f3ee08ee5b9ace1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: <class 'imbens.ensemble._under_sampling.balanced_random_forest.BalancedRandomForestClassifier'>\n",
      "dataset: us_crime\n",
      "Accuracy: 0.8430447979244594\n",
      "F1: 0.6838631417908656\n",
      "Precision: 0.6520783297130108\n",
      "Recall: 0.8569587310003535\n",
      "G-mean: 0.8547280648872416\n",
      "AUC: 0.9209093073720591\n",
      "AUPR: 0.5245437444198744\n",
      "Sensitivity: 0.8733333333333333\n",
      "Specificity: 0.8405841286673736\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T05:53:45.178810Z",
     "start_time": "2024-11-27T05:53:43.306367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs = []\n",
    "f1s = []\n",
    "precs = []\n",
    "recs = []\n",
    "gmeans = []\n",
    "aucs = []\n",
    "auprs = []\n",
    "sens = []\n",
    "spes = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = AdaCostClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    accs.append(accuracy_score(y_test, y_pred))\n",
    "    f1s.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    precs.append(precision_score(y_test, y_pred, average='macro'))\n",
    "    recs.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    gmeans.append(geometric_mean_score(y_test, y_pred))\n",
    "    aucs.append(roc_auc_score(y_test, y_pred_proba))\n",
    "    auprs.append(average_precision_score(y_test, y_pred_proba))\n",
    "    sens.append(sensitivity_score(y_test, y_pred))\n",
    "    spes.append(specificity_score(y_test, y_pred))\n",
    "    \n",
    "print('model:', model.__class__)\n",
    "print('dataset:', dataset_name)\n",
    "print('Accuracy:', np.mean(accs))\n",
    "print('F1:', np.mean(f1s))\n",
    "print('Precision:', np.mean(precs))\n",
    "print('Recall:', np.mean(recs))\n",
    "print('G-mean:', np.mean(gmeans))\n",
    "print('AUC:', np.mean(aucs))\n",
    "print('AUPR:', np.mean(auprs))\n",
    "print('Sensitivity:', np.mean(sens))\n",
    "print('Specificity:', np.mean(spes))"
   ],
   "id": "4c7a15a3b984c0aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: <class 'imbens.ensemble._reweighting.adacost.AdaCostClassifier'>\n",
      "dataset: us_crime\n",
      "Accuracy: 0.7547700910567877\n",
      "F1: 0.6058129769802194\n",
      "Precision: 0.6102703518112912\n",
      "Recall: 0.8306654294803817\n",
      "G-mean: 0.8237132009838211\n",
      "AUC: 0.8993123060759594\n",
      "AUPR: 0.48010208098213114\n",
      "Sensitivity: 0.9200000000000002\n",
      "Specificity: 0.7413308589607636\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T05:53:47.002137Z",
     "start_time": "2024-11-27T05:53:45.196537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs = []\n",
    "f1s = []\n",
    "precs = []\n",
    "recs = []\n",
    "gmeans = []\n",
    "aucs = []\n",
    "auprs = []\n",
    "sens = []\n",
    "spes = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = AdaUBoostClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    accs.append(accuracy_score(y_test, y_pred))\n",
    "    f1s.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    precs.append(precision_score(y_test, y_pred, average='macro'))\n",
    "    recs.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    gmeans.append(geometric_mean_score(y_test, y_pred))\n",
    "    aucs.append(roc_auc_score(y_test, y_pred_proba))\n",
    "    auprs.append(average_precision_score(y_test, y_pred_proba))\n",
    "    sens.append(sensitivity_score(y_test, y_pred))\n",
    "    spes.append(specificity_score(y_test, y_pred))\n",
    "    \n",
    "print('model:', model.__class__)\n",
    "print('dataset:', dataset_name)\n",
    "print('Accuracy:', np.mean(accs))\n",
    "print('F1:', np.mean(f1s))\n",
    "print('Precision:', np.mean(precs))\n",
    "print('Recall:', np.mean(recs))\n",
    "print('G-mean:', np.mean(gmeans))\n",
    "print('AUC:', np.mean(aucs))\n",
    "print('AUPR:', np.mean(auprs))\n",
    "print('Sensitivity:', np.mean(sens))\n",
    "print('Specificity:', np.mean(spes))"
   ],
   "id": "e3ed86ee7fe52f88",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: <class 'imbens.ensemble._reweighting.adauboost.AdaUBoostClassifier'>\n",
      "dataset: us_crime\n",
      "Accuracy: 0.8896663769977708\n",
      "F1: 0.7015328281536665\n",
      "Precision: 0.6716576228659632\n",
      "Recall: 0.7719247083775185\n",
      "G-mean: 0.7570863131333768\n",
      "AUC: 0.8924658300930837\n",
      "AUPR: 0.5282907834991026\n",
      "Sensitivity: 0.6333333333333333\n",
      "Specificity: 0.9105160834217039\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T05:53:48.870216Z",
     "start_time": "2024-11-27T05:53:47.018137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs = []\n",
    "f1s = []\n",
    "precs = []\n",
    "recs = []\n",
    "gmeans = []\n",
    "aucs = []\n",
    "auprs = []\n",
    "sens = []\n",
    "spes = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = AsymBoostClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    accs.append(accuracy_score(y_test, y_pred))\n",
    "    f1s.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    precs.append(precision_score(y_test, y_pred, average='macro'))\n",
    "    recs.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    gmeans.append(geometric_mean_score(y_test, y_pred))\n",
    "    aucs.append(roc_auc_score(y_test, y_pred_proba))\n",
    "    auprs.append(average_precision_score(y_test, y_pred_proba))\n",
    "    sens.append(sensitivity_score(y_test, y_pred))\n",
    "    spes.append(specificity_score(y_test, y_pred))\n",
    "    \n",
    "print('model:', model.__class__)\n",
    "print('dataset:', dataset_name)\n",
    "print('Accuracy:', np.mean(accs))\n",
    "print('F1:', np.mean(f1s))\n",
    "print('Precision:', np.mean(precs))\n",
    "print('Recall:', np.mean(recs))\n",
    "print('G-mean:', np.mean(gmeans))\n",
    "print('AUC:', np.mean(aucs))\n",
    "print('AUPR:', np.mean(auprs))\n",
    "print('Sensitivity:', np.mean(sens))\n",
    "print('Specificity:', np.mean(spes))"
   ],
   "id": "d7be5d8bd94ed8a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: <class 'imbens.ensemble._reweighting.asymmetric_boost.AsymBoostClassifier'>\n",
      "dataset: us_crime\n",
      "Accuracy: 0.9177453684462412\n",
      "F1: 0.7259897899168758\n",
      "Precision: 0.7218746721494678\n",
      "Recall: 0.7411754742547425\n",
      "G-mean: 0.7096823647545796\n",
      "AUC: 0.8981502101252896\n",
      "AUPR: 0.5441736331983217\n",
      "Sensitivity: 0.5333333333333334\n",
      "Specificity: 0.9490176151761517\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T11:46:48.956168Z",
     "start_time": "2024-11-24T11:46:13.417216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score, f1_score, confusion_matrix\n",
    "from imbens.ensemble import (\n",
    "    BalanceCascadeClassifier,\n",
    "    SelfPacedEnsembleClassifier,\n",
    "    UnderBaggingClassifier,\n",
    "    EasyEnsembleClassifier,\n",
    "    RUSBoostClassifier,\n",
    "    BalancedRandomForestClassifier,\n",
    "    AdaCostClassifier,\n",
    "    AdaUBoostClassifier,\n",
    "    AsymBoostClassifier\n",
    ")\n",
    "from UADF import DualGranularBalancedDeepForest\n",
    "from demo import get_config\n",
    "\n",
    "# 生成棋盘数据集\n",
    "def generate_checkerboard_data(n_samples=11000):\n",
    "    X, y = make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=2,\n",
    "        n_informative=2,\n",
    "        n_redundant=0,\n",
    "        n_clusters_per_class=1,\n",
    "        weights=[0.9, 0.1],\n",
    "        class_sep=1.0,\n",
    "        random_state=42\n",
    "    )\n",
    "    return X, y\n",
    "\n",
    "# 定义评估函数\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    auc = average_precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    g_mean = np.sqrt((tp / (tp + fn)) * (tn / (tn + fp)))\n",
    "    return {'AUCPRC': auc, 'F1': f1, 'G-Mean': g_mean}\n",
    "\n",
    "# 配置不平衡数据处理模型\n",
    "ensemble_methods = {\n",
    "    'BalanceCascade': BalanceCascadeClassifier(),\n",
    "    'SelfPacedEnsemble': SelfPacedEnsembleClassifier(),\n",
    "    'UnderBagging': UnderBaggingClassifier(),\n",
    "    'EasyEnsemble': EasyEnsembleClassifier(),\n",
    "    'RUSBoost': RUSBoostClassifier(),\n",
    "    'BalancedRandomForest': BalancedRandomForestClassifier(),\n",
    "    'AdaCost': AdaCostClassifier(),\n",
    "    'AdaUBoost': AdaUBoostClassifier(),\n",
    "    'AsymBoost': AsymBoostClassifier(),\n",
    "    'DualGranularBalancedDeepForest': DualGranularBalancedDeepForest(get_config())\n",
    "}\n",
    "\n",
    "# 加载数据集\n",
    "X, y = generate_checkerboard_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 对每个集成方法进行训练和评估\n",
    "results = {}\n",
    "for method_name, model in ensemble_methods.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    results[method_name] = evaluate_model(model, X_test, y_test)\n",
    "\n",
    "# 输出结果\n",
    "for method_name, metrics in results.items():\n",
    "    print(f\"Method: {method_name}\")\n",
    "    print(f\"  AUCPRC: {metrics['AUCPRC']:.3f}, F1: {metrics['F1']:.3f}, G-Mean: {metrics['G-Mean']:.3f}\")\n"
   ],
   "id": "58bf968d0e0a674b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority class detected: 0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Begin to train.... - 2024-11-24 19:46:16,452 - DualGranularBalancedDeepForest\n",
      "the shape of training samples: (7700, 2) - 2024-11-24 19:46:16,453 - DualGranularBalancedDeepForest\n",
      "use f1_macro as training evaluation - 2024-11-24 19:46:16,453 - DualGranularBalancedDeepForest\n",
      "stacking: False, save model: False - 2024-11-24 19:46:16,454 - DualGranularBalancedDeepForest\n",
      "-----------------------------------------layer-0-------------------------------------------- - 2024-11-24 19:46:16,454 - DualGranularBalancedDeepForest\n",
      "The shape of x_train is (7700, 2) - 2024-11-24 19:46:16,454 - DualGranularBalancedDeepForest\n",
      "layer_0, estimator_0, BalancedEnsembleClassifier, n_fold_0,Accuracy=0.9747, f1_score=0.9336, auc=0.9647, gmean=0.9543, sen=0.9295, spe=0.9798, aupr=0.9116 - 2024-11-24 19:46:20,413 - KFoldWrapper\n",
      "layer_0, estimator_0, BalancedEnsembleClassifier, n_fold_1,Accuracy=0.9740, f1_score=0.9335, auc=0.9708, gmean=0.9656, sen=0.9551, spe=0.9762, aupr=0.9112 - 2024-11-24 19:46:20,417 - KFoldWrapper\n",
      "layer_0, estimator_0, BalancedEnsembleClassifier, n_fold_2,Accuracy=0.9734, f1_score=0.9317, auc=0.9769, gmean=0.9623, sen=0.9487, spe=0.9762, aupr=0.9146 - 2024-11-24 19:46:20,421 - KFoldWrapper\n",
      "layer_0, estimator_0, BalancedEnsembleClassifier, n_fold_3,Accuracy=0.9656, f1_score=0.9122, auc=0.9476, gmean=0.9408, sen=0.9108, spe=0.9718, aupr=0.8991 - 2024-11-24 19:46:20,426 - KFoldWrapper\n",
      "layer_0, estimator_0, BalancedEnsembleClassifier, n_fold_4,Accuracy=0.9701, f1_score=0.9240, auc=0.9659, gmean=0.9550, sen=0.9363, spe=0.9740, aupr=0.9055 - 2024-11-24 19:46:20,431 - KFoldWrapper\n",
      "layer_0, estimator_0, BalancedEnsembleClassifier, wrapper,Accuracy=0.9716, f1_score=0.9270, auc=0.9650, gmean=0.9556, sen=0.9361, spe=0.9756, aupr=0.9081 - 2024-11-24 19:46:20,440 - KFoldWrapper\n",
      "---------- - 2024-11-24 19:46:20,441 - KFoldWrapper\n",
      "layer_0, estimator_1, BalancedEnsembleClassifier, n_fold_0,Accuracy=0.9753, f1_score=0.9375, auc=0.9793, gmean=0.9749, sen=0.9744, spe=0.9754, aupr=0.9242 - 2024-11-24 19:46:24,443 - KFoldWrapper\n",
      "layer_0, estimator_1, BalancedEnsembleClassifier, n_fold_1,Accuracy=0.9760, f1_score=0.9380, auc=0.9713, gmean=0.9667, sen=0.9551, spe=0.9783, aupr=0.9217 - 2024-11-24 19:46:24,449 - KFoldWrapper\n",
      "layer_0, estimator_1, BalancedEnsembleClassifier, n_fold_2,Accuracy=0.9721, f1_score=0.9284, auc=0.9632, gmean=0.9587, sen=0.9423, spe=0.9754, aupr=0.8973 - 2024-11-24 19:46:24,454 - KFoldWrapper\n",
      "layer_0, estimator_1, BalancedEnsembleClassifier, n_fold_3,Accuracy=0.9773, f1_score=0.9388, auc=0.9524, gmean=0.9441, sen=0.9045, spe=0.9855, aupr=0.8870 - 2024-11-24 19:46:24,460 - KFoldWrapper\n",
      "layer_0, estimator_1, BalancedEnsembleClassifier, n_fold_4,Accuracy=0.9740, f1_score=0.9321, auc=0.9672, gmean=0.9512, sen=0.9236, spe=0.9798, aupr=0.9202 - 2024-11-24 19:46:24,465 - KFoldWrapper\n",
      "layer_0, estimator_1, BalancedEnsembleClassifier, wrapper,Accuracy=0.9749, f1_score=0.9349, auc=0.9663, gmean=0.9592, sen=0.9399, spe=0.9789, aupr=0.9096 - 2024-11-24 19:46:24,472 - KFoldWrapper\n",
      "---------- - 2024-11-24 19:46:24,473 - KFoldWrapper\n",
      "layer_0, estimator_2, BalancedEnsembleClassifier, n_fold_0,Accuracy=0.9714, f1_score=0.9269, auc=0.9697, gmean=0.9584, sen=0.9423, spe=0.9747, aupr=0.8813 - 2024-11-24 19:46:28,504 - KFoldWrapper\n",
      "layer_0, estimator_2, BalancedEnsembleClassifier, n_fold_1,Accuracy=0.9708, f1_score=0.9250, auc=0.9637, gmean=0.9551, sen=0.9359, spe=0.9747, aupr=0.8947 - 2024-11-24 19:46:28,509 - KFoldWrapper\n",
      "layer_0, estimator_2, BalancedEnsembleClassifier, n_fold_2,Accuracy=0.9825, f1_score=0.9528, auc=0.9795, gmean=0.9615, sen=0.9359, spe=0.9877, aupr=0.9415 - 2024-11-24 19:46:28,513 - KFoldWrapper\n",
      "layer_0, estimator_2, BalancedEnsembleClassifier, n_fold_3,Accuracy=0.9714, f1_score=0.9269, auc=0.9564, gmean=0.9557, sen=0.9363, spe=0.9754, aupr=0.9054 - 2024-11-24 19:46:28,518 - KFoldWrapper\n",
      "layer_0, estimator_2, BalancedEnsembleClassifier, n_fold_4,Accuracy=0.9688, f1_score=0.9198, auc=0.9594, gmean=0.9455, sen=0.9172, spe=0.9747, aupr=0.9138 - 2024-11-24 19:46:28,523 - KFoldWrapper\n",
      "layer_0, estimator_2, BalancedEnsembleClassifier, wrapper,Accuracy=0.9730, f1_score=0.9301, auc=0.9656, gmean=0.9552, sen=0.9335, spe=0.9775, aupr=0.9073 - 2024-11-24 19:46:28,530 - KFoldWrapper\n",
      "---------- - 2024-11-24 19:46:28,531 - KFoldWrapper\n",
      "layer_0, estimator_3, BalancedEnsembleClassifier, n_fold_0,Accuracy=0.9766, f1_score=0.9386, auc=0.9590, gmean=0.9583, sen=0.9359, spe=0.9812, aupr=0.9169 - 2024-11-24 19:46:33,181 - KFoldWrapper\n",
      "layer_0, estimator_3, BalancedEnsembleClassifier, n_fold_1,Accuracy=0.9734, f1_score=0.9310, auc=0.9598, gmean=0.9565, sen=0.9359, spe=0.9776, aupr=0.9345 - 2024-11-24 19:46:33,186 - KFoldWrapper\n",
      "layer_0, estimator_3, BalancedEnsembleClassifier, n_fold_2,Accuracy=0.9714, f1_score=0.9261, auc=0.9634, gmean=0.9525, sen=0.9295, spe=0.9762, aupr=0.8791 - 2024-11-24 19:46:33,190 - KFoldWrapper\n",
      "layer_0, estimator_3, BalancedEnsembleClassifier, n_fold_3,Accuracy=0.9773, f1_score=0.9414, auc=0.9760, gmean=0.9675, sen=0.9554, spe=0.9798, aupr=0.9464 - 2024-11-24 19:46:33,195 - KFoldWrapper\n",
      "layer_0, estimator_3, BalancedEnsembleClassifier, n_fold_4,Accuracy=0.9753, f1_score=0.9365, auc=0.9644, gmean=0.9636, sen=0.9490, spe=0.9783, aupr=0.9085 - 2024-11-24 19:46:33,201 - KFoldWrapper\n",
      "layer_0, estimator_3, BalancedEnsembleClassifier, wrapper,Accuracy=0.9748, f1_score=0.9347, auc=0.9644, gmean=0.9597, sen=0.9412, spe=0.9786, aupr=0.9163 - 2024-11-24 19:46:33,209 - KFoldWrapper\n",
      "---------- - 2024-11-24 19:46:33,210 - KFoldWrapper\n",
      "The evaluation[f1_macro] of layer_0 is 0.9392 - 2024-11-24 19:46:34,231 - DualGranularBalancedDeepForest\n",
      "-----------------------------------------layer-1-------------------------------------------- - 2024-11-24 19:46:34,232 - DualGranularBalancedDeepForest\n",
      "The shape of x_train is (7700, 2) - 2024-11-24 19:46:34,233 - DualGranularBalancedDeepForest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final enhanced_vector_cur_layer type: <class 'numpy.ndarray'>\n",
      "enhanced_vector_cur_layer shape: (7700, 10)\n",
      "num_layers_before_append: 0\n",
      "num_layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "layer_1, estimator_0, BalancedEnsembleClassifier, n_fold_0,Accuracy=0.9851, f1_score=0.9582, auc=0.9680, gmean=0.9480, sen=0.9038, spe=0.9942, aupr=0.9169 - 2024-11-24 19:46:38,549 - KFoldWrapper\n",
      "layer_1, estimator_0, BalancedEnsembleClassifier, n_fold_1,Accuracy=0.9760, f1_score=0.9294, auc=0.9575, gmean=0.8964, sen=0.8077, spe=0.9949, aupr=0.8877 - 2024-11-24 19:46:38,554 - KFoldWrapper\n",
      "layer_1, estimator_0, BalancedEnsembleClassifier, n_fold_2,Accuracy=0.9825, f1_score=0.9523, auc=0.9769, gmean=0.9555, sen=0.9231, spe=0.9892, aupr=0.9137 - 2024-11-24 19:46:38,560 - KFoldWrapper\n",
      "layer_1, estimator_0, BalancedEnsembleClassifier, n_fold_3,Accuracy=0.9721, f1_score=0.9227, auc=0.9678, gmean=0.9141, sen=0.8471, spe=0.9863, aupr=0.8912 - 2024-11-24 19:46:38,565 - KFoldWrapper\n",
      "layer_1, estimator_0, BalancedEnsembleClassifier, n_fold_4,Accuracy=0.9766, f1_score=0.9331, auc=0.9490, gmean=0.9101, sen=0.8344, spe=0.9928, aupr=0.8765 - 2024-11-24 19:46:38,569 - KFoldWrapper\n",
      "layer_1, estimator_0, BalancedEnsembleClassifier, wrapper,Accuracy=0.9784, f1_score=0.9393, auc=0.9638, gmean=0.9251, sen=0.8632, spe=0.9915, aupr=0.8969 - 2024-11-24 19:46:38,579 - KFoldWrapper\n",
      "---------- - 2024-11-24 19:46:38,580 - KFoldWrapper\n",
      "layer_1, estimator_1, BalancedEnsembleClassifier, n_fold_0,Accuracy=0.9714, f1_score=0.9178, auc=0.9583, gmean=0.8942, sen=0.8077, spe=0.9899, aupr=0.8709 - 2024-11-24 19:46:42,944 - KFoldWrapper\n",
      "layer_1, estimator_1, BalancedEnsembleClassifier, n_fold_1,Accuracy=0.9818, f1_score=0.9480, auc=0.9708, gmean=0.9279, sen=0.8654, spe=0.9949, aupr=0.9255 - 2024-11-24 19:46:42,949 - KFoldWrapper\n",
      "layer_1, estimator_1, BalancedEnsembleClassifier, n_fold_2,Accuracy=0.9753, f1_score=0.9302, auc=0.9631, gmean=0.9152, sen=0.8462, spe=0.9899, aupr=0.8834 - 2024-11-24 19:46:42,954 - KFoldWrapper\n",
      "layer_1, estimator_1, BalancedEnsembleClassifier, n_fold_3,Accuracy=0.9812, f1_score=0.9460, auc=0.9779, gmean=0.9218, sen=0.8535, spe=0.9957, aupr=0.9361 - 2024-11-24 19:46:42,959 - KFoldWrapper\n",
      "layer_1, estimator_1, BalancedEnsembleClassifier, n_fold_4,Accuracy=0.9747, f1_score=0.9299, auc=0.9589, gmean=0.9216, sen=0.8599, spe=0.9877, aupr=0.8793 - 2024-11-24 19:46:42,964 - KFoldWrapper\n",
      "layer_1, estimator_1, BalancedEnsembleClassifier, wrapper,Accuracy=0.9769, f1_score=0.9343, auc=0.9658, gmean=0.9162, sen=0.8465, spe=0.9916, aupr=0.8985 - 2024-11-24 19:46:42,972 - KFoldWrapper\n",
      "---------- - 2024-11-24 19:46:42,972 - KFoldWrapper\n",
      "layer_1, estimator_2, BalancedEnsembleClassifier, n_fold_0,Accuracy=0.9734, f1_score=0.9222, auc=0.9625, gmean=0.8919, sen=0.8013, spe=0.9928, aupr=0.8762 - 2024-11-24 19:46:47,224 - KFoldWrapper\n",
      "layer_1, estimator_2, BalancedEnsembleClassifier, n_fold_1,Accuracy=0.9825, f1_score=0.9503, auc=0.9718, gmean=0.9344, sen=0.8782, spe=0.9942, aupr=0.9306 - 2024-11-24 19:46:47,228 - KFoldWrapper\n",
      "layer_1, estimator_2, BalancedEnsembleClassifier, n_fold_2,Accuracy=0.9727, f1_score=0.9191, auc=0.9586, gmean=0.8818, sen=0.7821, spe=0.9942, aupr=0.8971 - 2024-11-24 19:46:47,233 - KFoldWrapper\n",
      "layer_1, estimator_2, BalancedEnsembleClassifier, n_fold_3,Accuracy=0.9766, f1_score=0.9315, auc=0.9643, gmean=0.8974, sen=0.8089, spe=0.9957, aupr=0.9039 - 2024-11-24 19:46:47,237 - KFoldWrapper\n",
      "layer_1, estimator_2, BalancedEnsembleClassifier, n_fold_4,Accuracy=0.9766, f1_score=0.9323, auc=0.9697, gmean=0.9038, sen=0.8217, spe=0.9942, aupr=0.8985 - 2024-11-24 19:46:47,243 - KFoldWrapper\n",
      "layer_1, estimator_2, BalancedEnsembleClassifier, wrapper,Accuracy=0.9764, f1_score=0.9312, auc=0.9653, gmean=0.9020, sen=0.8184, spe=0.9942, aupr=0.9007 - 2024-11-24 19:46:47,252 - KFoldWrapper\n",
      "---------- - 2024-11-24 19:46:47,253 - KFoldWrapper\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 64\u001B[0m\n\u001B[0;32m     62\u001B[0m results \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m method_name, model \u001B[38;5;129;01min\u001B[39;00m ensemble_methods\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m---> 64\u001B[0m     \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     65\u001B[0m     results[method_name] \u001B[38;5;241m=\u001B[39m evaluate_model(model, X_test, y_test)\n\u001B[0;32m     67\u001B[0m \u001B[38;5;66;03m# 输出结果\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\DGBDF\\model\\DualGranularBalancedDeepForest.py:374\u001B[0m, in \u001B[0;36mDualGranularBalancedDeepForest.fit\u001B[1;34m(self, x_train, y_train)\u001B[0m\n\u001B[0;32m    372\u001B[0m     buckets \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    373\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 374\u001B[0m     bucket_variances, loss_A_B_stats, all_instance_B, all_instance_u \u001B[38;5;241m=\u001B[39m \u001B[43merror_to_uncertainty\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbuckets\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    376\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m depth \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    377\u001B[0m         uncertainty_for_class_1, resort_idx_for_class_1 \u001B[38;5;241m=\u001B[39m error_to_uncertainty_for_class_1(\n\u001B[0;32m    378\u001B[0m             index_1_sorted, hardness_1_sorted)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\DGBDF\\model\\DualGranularBalancedDeepForest.py:350\u001B[0m, in \u001B[0;36mDualGranularBalancedDeepForest.fit.<locals>.error_to_uncertainty\u001B[1;34m(buckets)\u001B[0m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(cur_bucket_sample_uncertainty) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(bucket):\n\u001B[0;32m    347\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    348\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMismatch before sorting: len(cur_bucket_sample_uncertainty) = \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(cur_bucket_sample_uncertainty)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, len(bucket) = \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(bucket)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 350\u001B[0m sorted_sample_idx \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margsort\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcur_bucket_sample_uncertainty\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    351\u001B[0m \u001B[38;5;66;03m# print(\u001B[39;00m\n\u001B[0;32m    352\u001B[0m \u001B[38;5;66;03m#     f\"Before sorting, bucket[{i}] length: {len(bucket)}, cur_bucket_sample_uncertainty length: {len(cur_bucket_sample_uncertainty)}\")\u001B[39;00m\n\u001B[0;32m    353\u001B[0m buckets[i] \u001B[38;5;241m=\u001B[39m [bucket[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m sorted_sample_idx]\n",
      "File \u001B[1;32m<__array_function__ internals>:200\u001B[0m, in \u001B[0;36margsort\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\machine-learning\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1146\u001B[0m, in \u001B[0;36margsort\u001B[1;34m(a, axis, kind, order)\u001B[0m\n\u001B[0;32m   1038\u001B[0m \u001B[38;5;129m@array_function_dispatch\u001B[39m(_argsort_dispatcher)\n\u001B[0;32m   1039\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21margsort\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, kind\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, order\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   1040\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1041\u001B[0m \u001B[38;5;124;03m    Returns the indices that would sort an array.\u001B[39;00m\n\u001B[0;32m   1042\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1144\u001B[0m \n\u001B[0;32m   1145\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1146\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_wrapfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43margsort\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkind\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkind\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\machine-learning\\lib\\site-packages\\numpy\\core\\fromnumeric.py:54\u001B[0m, in \u001B[0;36m_wrapfunc\u001B[1;34m(obj, method, *args, **kwds)\u001B[0m\n\u001B[0;32m     52\u001B[0m bound \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(obj, method, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m bound \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 54\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _wrapit(obj, method, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     57\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m bound(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\machine-learning\\lib\\site-packages\\numpy\\core\\fromnumeric.py:43\u001B[0m, in \u001B[0;36m_wrapit\u001B[1;34m(obj, method, *args, **kwds)\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m:\n\u001B[0;32m     42\u001B[0m     wrap \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m---> 43\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(asarray(obj), method)(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m     44\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m wrap:\n\u001B[0;32m     45\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, mu\u001B[38;5;241m.\u001B[39mndarray):\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score, f1_score, confusion_matrix\n",
    "from imbens.ensemble import (\n",
    "    BalanceCascadeClassifier,\n",
    "    SelfPacedEnsembleClassifier,\n",
    "    UnderBaggingClassifier,\n",
    "    EasyEnsembleClassifier,\n",
    "    RUSBoostClassifier,\n",
    "    BalancedRandomForestClassifier,\n",
    "    AdaCostClassifier,\n",
    "    AdaUBoostClassifier,\n",
    "    AsymBoostClassifier\n",
    ")\n",
    "from UADF import DualGranularBalancedDeepForest\n",
    "from demo import get_config\n",
    "\n",
    "# 生成棋盘数据集\n",
    "def generate_checkerboard_data(n_samples=11000):\n",
    "    X, y = make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=2,\n",
    "        n_informative=2,\n",
    "        n_redundant=0,\n",
    "        n_clusters_per_class=1,\n",
    "        weights=[0.9, 0.1],\n",
    "        class_sep=1.0,\n",
    "        random_state=42\n",
    "    )\n",
    "    return X, y\n",
    "\n",
    "# 定义评估函数\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    auc = average_precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    g_mean = np.sqrt((tp / (tp + fn)) * (tn / (tn + fp)))\n",
    "    return {'AUCPRC': auc, 'F1': f1, 'G-Mean': g_mean}\n",
    "\n",
    "# 可视化函数，展示每个方法在不同阶段的分类结果\n",
    "def visualize_model_stages(model, X_train, y_train, X_test, y_test, method_name, n_stages=3):\n",
    "    fig, axes = plt.subplots(1, n_stages, figsize=(15, 5))\n",
    "    for stage in range(n_stages):\n",
    "        # 模拟每个阶段的结果，通过部分训练数据集来可视化\n",
    "        sample_indices = np.random.choice(len(X_train), size=int(len(X_train) * (stage + 1) / n_stages), replace=False)\n",
    "        X_stage, y_stage = X_train[sample_indices], y_train[sample_indices]\n",
    "        \n",
    "        model.fit(X_stage, y_stage)  # 部分训练数据拟合\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # 绘制测试集的预测结果\n",
    "        scatter = axes[stage].scatter(X_test[:, 0], X_test[:, 1], c=y_pred, cmap='coolwarm', alpha=0.6)\n",
    "        axes[stage].scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='coolwarm', edgecolor='k', alpha=0.3)\n",
    "        axes[stage].set_title(f\"{method_name} - Stage {stage + 1}\")\n",
    "        fig.colorbar(scatter, ax=axes[stage], orientation='vertical')\n",
    "\n",
    "    plt.suptitle(f\"Classification Stages for {method_name}\")\n",
    "    plt.show()\n",
    "\n",
    "# 配置不平衡数据处理模型\n",
    "ensemble_methods = {\n",
    "    'BalanceCascade': BalanceCascadeClassifier(),\n",
    "    'SelfPacedEnsemble': SelfPacedEnsembleClassifier(),\n",
    "    'UnderBagging': UnderBaggingClassifier(),\n",
    "    'EasyEnsemble': EasyEnsembleClassifier(),\n",
    "    'RUSBoost': RUSBoostClassifier(),\n",
    "    'BalancedRandomForest': BalancedRandomForestClassifier(),\n",
    "    'AdaCost': AdaCostClassifier(),\n",
    "    'AdaUBoost': AdaUBoostClassifier(),\n",
    "    'AsymBoost': AsymBoostClassifier(),\n",
    "    'DualGranularBalancedDeepForest': DualGranularBalancedDeepForest(get_config())\n",
    "}\n",
    "\n",
    "# 加载数据集\n",
    "X, y = generate_checkerboard_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 对每个集成方法进行训练、评估和可视化\n",
    "results = {}\n",
    "for method_name, model in ensemble_methods.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    results[method_name] = evaluate_model(model, X_test, y_test)\n",
    "    # 可视化该模型在不同阶段的结果\n",
    "    visualize_model_stages(model, X_train, y_train, X_test, y_test, method_name)\n",
    "\n",
    "# 输出结果\n",
    "for method_name, metrics in results.items():\n",
    "    print(f\"Method: {method_name}\")\n",
    "    print(f\"  AUCPRC: {metrics['AUCPRC']:.3f}, F1: {metrics['F1']:.3f}, G-Mean: {metrics['G-Mean']:.3f}\")\n"
   ],
   "id": "2ae2ce286ccfaa87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score, f1_score, confusion_matrix\n",
    "from imbens.ensemble import (\n",
    "    BalanceCascadeClassifier,\n",
    "    SelfPacedEnsembleClassifier,\n",
    "    UnderBaggingClassifier,\n",
    "    EasyEnsembleClassifier,\n",
    "    RUSBoostClassifier,\n",
    "    BalancedRandomForestClassifier,\n",
    "    AdaCostClassifier,\n",
    "    AdaUBoostClassifier,\n",
    "    AsymBoostClassifier\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "\n",
    "# 生成棋盘数据集\n",
    "def generate_checkerboard_data(n_samples=1600):\n",
    "    centers = [(i, j) for i in range(4) for j in range(4)]\n",
    "    X, y = make_blobs(n_samples=n_samples, centers=centers, cluster_std=0.5, random_state=42)\n",
    "    y = (y % 2).astype(int)  # 交替将类标签设为0和1，形成棋盘格子\n",
    "    return X, y\n",
    "\n",
    "# 定义评估函数\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    auc = average_precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    g_mean = np.sqrt((tp / (tp + fn)) * (tn / (tn + fp)))\n",
    "    return {'AUCPRC': auc, 'F1': f1, 'G-Mean': g_mean}\n",
    "\n",
    "# 绘制数据集和预测结果\n",
    "def plot_checkerboard(X, y, title, ax):\n",
    "    scatter = ax.scatter(X[:, 0], X[:, 1], c=y, cmap='coolwarm', alpha=0.6, edgecolor='k')\n",
    "    ax.set_title(title)\n",
    "    plt.colorbar(scatter, ax=ax, orientation='vertical')\n",
    "\n",
    "# 可视化方法的不同阶段\n",
    "def visualize_method_stages(X_train, y_train, method_name, stages):\n",
    "    fig, axes = plt.subplots(1, len(stages), figsize=(15, 5))\n",
    "    for i, (title, X_stage, y_stage) in enumerate(stages):\n",
    "        plot_checkerboard(X_stage, y_stage, f\"{method_name} - {title}\", axes[i])\n",
    "    plt.show()\n",
    "\n",
    "# 配置数据集和方法\n",
    "X, y = generate_checkerboard_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 不平衡处理方法的不同阶段可视化\n",
    "# 1. Clean 方法\n",
    "ncr = NeighbourhoodCleaningRule()\n",
    "X_clean, y_clean = ncr.fit_resample(X_train, y_train)\n",
    "visualize_method_stages(X_train, y_train, \"Clean\", [(\"Original\", X_train, y_train), (\"After Cleaning\", X_clean, y_clean)])\n",
    "\n",
    "# 2. SMOTE 方法\n",
    "smote = SMOTE()\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
    "visualize_method_stages(X_train, y_train, \"SMOTE\", [(\"Original\", X_train, y_train), (\"After SMOTE\", X_smote, y_smote)])\n",
    "\n",
    "# 3. Easy Ensemble 方法\n",
    "easy_ensemble = EasyEnsembleClassifier(n_estimators=3)\n",
    "easy_ensemble.fit(X_train, y_train)\n",
    "stages_easy = [(\"Stage 1\", X_train, y_train)]\n",
    "for i, estimator in enumerate(easy_ensemble.estimators_):\n",
    "    X_easy, y_easy = estimator[0].fit_resample(X_train, y_train)\n",
    "    stages_easy.append((f\"Stage {i + 2}\", X_easy, y_easy))\n",
    "visualize_method_stages(X_train, y_train, \"EasyEnsemble\", stages_easy)\n",
    "\n",
    "# 4. Cascade 方法\n",
    "cascade = BalanceCascadeClassifier(n_estimators=3)\n",
    "cascade.fit(X_train, y_train)\n",
    "stages_cascade = [(\"Stage 1\", X_train, y_train)]\n",
    "for i, estimator in enumerate(cascade.estimators_):\n",
    "    X_cascade, y_cascade = estimator[0].fit_resample(X_train, y_train)\n",
    "    stages_cascade.append((f\"Stage {i + 2}\", X_cascade, y_cascade))\n",
    "visualize_method_stages(X_train, y_train, \"Cascade\", stages_cascade)\n",
    "\n",
    "# 5. Self-Paced Ensemble (SPE) 方法\n",
    "spe = SelfPacedEnsembleClassifier(n_estimators=3)\n",
    "spe.fit(X_train, y_train)\n",
    "stages_spe = [(\"Stage 1\", X_train, y_train)]\n",
    "for i, estimator in enumerate(spe.estimators_):\n",
    "    X_spe, y_spe = estimator[0].fit_resample(X_train, y_train)\n",
    "    stages_spe.append((f\"Stage {i + 2}\", X_spe, y_spe))\n",
    "visualize_method_stages(X_train, y_train, \"SelfPacedEnsemble\", stages_spe)\n"
   ],
   "id": "d8b55aed581fd85c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 生成严格交替分布的棋盘数据集\n",
    "def generate_strict_checkerboard_data(n_samples_per_blob=500, grid_size=4, cluster_std=0.05):\n",
    "    centers = []\n",
    "    labels = []\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            centers.append((i, j))\n",
    "            labels.append((i + j) % 2)  # 交替标签，确保相邻格子颜色不同\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    for center, label in zip(centers, labels):\n",
    "        X_blob = np.random.multivariate_normal(center, np.eye(2) * cluster_std, n_samples_per_blob)\n",
    "        X.extend(X_blob)\n",
    "        y.extend([label] * n_samples_per_blob)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# 加载数据集\n",
    "X, y = generate_strict_checkerboard_data()\n",
    "\n",
    "# 可视化生成的棋盘数据集\n",
    "plt.figure(figsize=(6, 6))\n",
    "scatter = plt.scatter(X[:, 0], X[:, 1], c=y, cmap='coolwarm', alpha=0.6, edgecolor='k')\n",
    "plt.title(\"Generated Checkerboard Dataset (Strict Alternating Pattern)\")\n",
    "plt.colorbar(scatter, orientation='vertical', label='Class Label')\n",
    "plt.show()\n"
   ],
   "id": "6638265821db4025",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score, f1_score, confusion_matrix\n",
    "from imbens.ensemble import (\n",
    "    BalanceCascadeClassifier,\n",
    "    SelfPacedEnsembleClassifier,\n",
    "    UnderBaggingClassifier,\n",
    "    EasyEnsembleClassifier,\n",
    "    RUSBoostClassifier,\n",
    "    BalancedRandomForestClassifier,\n",
    "    AdaCostClassifier,\n",
    "    AdaUBoostClassifier,\n",
    "    AsymBoostClassifier\n",
    ")\n",
    "from UADF import DualGranularBalancedDeepForest\n",
    "from demo import get_config\n",
    "import os\n",
    "\n",
    "# 定义评估函数\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    auc = average_precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    g_mean = np.sqrt((tp / (tp + fn)) * (tn / (tn + fp)))\n",
    "    return {'AUCPRC': auc, 'F1': f1, 'G-Mean': g_mean}, y_pred\n",
    "\n",
    "# 配置不平衡数据处理模型\n",
    "ensemble_methods = {\n",
    "    'BalanceCascade': BalanceCascadeClassifier(),\n",
    "    'SelfPacedEnsemble': SelfPacedEnsembleClassifier(),\n",
    "    'UnderBagging': UnderBaggingClassifier(),\n",
    "    'EasyEnsemble': EasyEnsembleClassifier(),\n",
    "    'RUSBoost': RUSBoostClassifier(),\n",
    "    'BalancedRandomForest': BalancedRandomForestClassifier(),\n",
    "    'AdaCost': AdaCostClassifier(),\n",
    "    'AdaUBoost': AdaUBoostClassifier(),\n",
    "    'AsymBoost': AsymBoostClassifier(),\n",
    "    'DualGranularBalancedDeepForest': DualGranularBalancedDeepForest(get_config())\n",
    "}\n",
    "\n",
    "# 加载不平衡的棋盘数据集\n",
    "def generate_imbalanced_checkerboard_data(n_samples_class0=10000, n_samples_class1=1000, grid_size=3, cluster_std=0.03):\n",
    "    centers = []\n",
    "    labels = []\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            centers.append((i, j))\n",
    "            labels.append((i + j) % 2)  # 交替标签，确保相邻格子颜色不同\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    for center, label in zip(centers, labels):\n",
    "        n_samples = n_samples_class0 if label == 0 else n_samples_class1  # 根据标签分配不同的样本数\n",
    "        X_blob = np.random.multivariate_normal(center, np.eye(2) * cluster_std, n_samples)\n",
    "        X.extend(X_blob)\n",
    "        y.extend([label] * n_samples)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# 创建用于保存图像和数据的文件夹\n",
    "output_dir = \"pred_results2\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 生成数据并划分训练集和测试集\n",
    "X, y = generate_imbalanced_checkerboard_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# 保存生成的原始数据集\n",
    "np.save(os.path.join(output_dir, \"X.npy\"), X)\n",
    "np.save(os.path.join(output_dir, \"y.npy\"), y)\n",
    "\n",
    "# 可视化生成的棋盘数据集并显示和保存为 PNG\n",
    "plt.figure(figsize=(6, 6))\n",
    "scatter = plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap='coolwarm', alpha=0.6, edgecolor='k')\n",
    "plt.title(\"Generated Checkerboard Dataset (Strict Alternating Pattern)\")\n",
    "plt.colorbar(scatter, orientation='vertical', label='Class Label')\n",
    "plt.savefig(os.path.join(output_dir, \"Generated_Checkerboard_Dataset.png\"), format=\"png\")\n",
    "plt.show()\n",
    "\n",
    "# 对每个集成方法进行训练、评估、可视化并保存结果\n",
    "results = {}\n",
    "for method_name, model in ensemble_methods.items():\n",
    "    print(f\"Training {method_name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    metrics, y_pred = evaluate_model(model, X_test, y_test)\n",
    "    results[method_name] = metrics\n",
    "\n",
    "    # 保存预测结果\n",
    "    np.save(os.path.join(output_dir, f\"{method_name}_y_pred.npy\"), y_pred)\n",
    "\n",
    "    # 可视化分类结果并保存为 PNG\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    scatter = plt.scatter(X_test[:, 0], X_test[:, 1], c=y_pred, cmap='coolwarm', alpha=0.6, edgecolor='k')\n",
    "    plt.title(f\"{method_name} - Classification Result\")\n",
    "    plt.colorbar(scatter, orientation='vertical', label='Predicted Class')\n",
    "    plt.savefig(os.path.join(output_dir, f\"{method_name}_Classification_Result.png\"), format=\"png\")\n",
    "    plt.show()\n",
    "\n",
    "# 输出结果\n",
    "for method_name, metrics in results.items():\n",
    "    print(f\"Method: {method_name}\")\n",
    "    print(f\"  AUCPRC: {metrics['AUCPRC']:.3f}, F1: {metrics['F1']:.3f}, G-Mean: {metrics['G-Mean']:.3f}\")\n"
   ],
   "id": "54de22fefab3678",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# 可视化深度森林采样的过程，和样本的Loss、Uncertainty\n",
   "id": "5bba95ec0c9b5028",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
